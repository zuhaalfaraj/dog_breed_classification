{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt   \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Breed_Classification(object):\n",
    "    \n",
    "    def __init__(self, img_path):\n",
    "        self.img_path = img_path\n",
    "        self.img = cv2.imread(self.img_path)\n",
    "        self.gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        VGG16 = models.vgg16(pretrained=True)\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.optimizer = optim.Adam(model_transfer.classifier.parameters(), lr=0.001)\n",
    "        self.loaders = self.initate_data\n",
    "        self.dataset = None\n",
    "\n",
    "\n",
    "    def face_detector(self,img_path = None):\n",
    "        \"\"\" returns ture if there a face is detected\n",
    "        Note: this function takes the path of images, \n",
    "        and it has a default image if there's no provided image  \n",
    "        \"\"\"\n",
    "        \n",
    "        if gray == None:\n",
    "            img_path = self.gray\n",
    "        else :\n",
    "            img = cv2.imread(self.img_path)\n",
    "            img_path = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "        faces = face_cascade.detectMultiScale(img_path)\n",
    "        return len(faces) > 0\n",
    "    \n",
    "    def VGG16_predict(self, img_path= None):\n",
    "        \"\"\"returns the index of the highest probability\n",
    "        Note: this function takes the path of images, \n",
    "        and it has a default image if there's no provided image  \n",
    "        \"\"\"  \n",
    "        if img_path == None:\n",
    "            img_path = self.img_path\n",
    "        else:\n",
    "            img_path = cv2.imread(self.img_path)          \n",
    "        \n",
    "        #Intiate vgg model\n",
    "        VGG16 = models.vgg16(pretrained=True)\n",
    "        if self.use_cuda:\n",
    "            VGG16 = VGG16.cuda()\n",
    "        #apply the model\n",
    "        image = Image.open(self.img_path)\n",
    "        in_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                           transforms.RandomResizedCrop(224),\n",
    "                                           transforms.ToTensor()])\n",
    "        image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            image= image.cuda()\n",
    "        VGG16.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        output = VGG16(image)\n",
    "            \n",
    "        return torch.argmax(output)\n",
    "    \n",
    "    def dog_detector(self, img_path=None):\n",
    "        \"\"\" returns True if the image is detected \"\"\"\n",
    "        if img_path ==None:\n",
    "            img_path = self.img_path\n",
    "        else:\n",
    "            img_path = cv2.imread(self.img_path)\n",
    "            \n",
    "        prediction = self.VGG16_predict(self.img_path)\n",
    "        return ((prediction <= 268) & (prediction >= 151))\n",
    "    \n",
    "    \n",
    "    def initate_data(self, data_dir, batch_size):    \n",
    "        \"\"\" it returns a dictionary of train, test, and valid data \n",
    "        Note: this function supposes that the supplied directory \n",
    "        contains a train, test, and valid folders inside it\n",
    "        \"\"\"\n",
    "        \n",
    "        data_dir = '/data/dog_images/'\n",
    "        images_dir = {'train_dir':os.path.join(data_dir,'train'), \n",
    "                      'test_dir':os.path.join(data_dir,'test'),\n",
    "                   'valid_dir':os.path.join(data_dir,'test') }\n",
    "        \n",
    "        normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        transformer = {\n",
    "        'train': transforms.Compose( [transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),normalization]),\n",
    "        'non-train': transforms.Compose([transforms.Resize(255), \n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),normalization])}\n",
    "        \n",
    "        self.dataset = {'train_data':datasets.ImageFolder(images_dir['train_dir'], \n",
    "                                                          transform=transformer['train']),\n",
    "                         'test_data': datasets.ImageFolder(images_dir['test_dir'],\n",
    "                                                           transform=transformer['non-train']),\n",
    "                         'valid_data': datasets.ImageFolder(images_dir['valid_dir'], \n",
    "                                                            transform=transformer['non-train'])}\n",
    "        \n",
    "        dataloader = {'trainloader': torch.utils.data.DataLoader(\n",
    "                        self.dataset['train_data'],\n",
    "                          batch_size=batch_size, shuffle=True),\n",
    "                      \n",
    "                    'testloader': torch.utils.data.DataLoader(\n",
    "                        self.dataset['test_data'],\n",
    "                        batch_size=batch_size, shuffle=True),\n",
    "                      \n",
    "                    'validloader': torch.utils.data.DataLoader(\n",
    "                        self.dataset['valid_data'],\n",
    "                        batch_size=batch_size, shuffle=True)}\n",
    "\n",
    "        return dataloader\n",
    "    \n",
    "    \n",
    "    def train(self, n_epochs, model,use_cuda, save_path, optimizer= None, criterion= None, loaders= None):\n",
    "        \"\"\"returns trained model\"\"\"\n",
    "        \n",
    "        if optimizer == None:\n",
    "            optimizer=self.optimizer\n",
    "        if criterion == None:\n",
    "            criterion= self.criterion\n",
    "        if loaders == None:\n",
    "             loaders=self.loaders      \n",
    "        # initialize tracker for minimum validation loss\n",
    "        valid_loss_min = np.Inf \n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            # initialize variables to monitor training and validation loss\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            # train the model #\n",
    "            model.train()\n",
    "            for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "                if self.use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "                \n",
    "                \n",
    "        # validate the model #\n",
    "            model.eval()\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                if self.use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss)) \n",
    "                \n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'\n",
    "                  .format(epoch, train_loss,\n",
    "                          valid_loss))\n",
    "            \n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
    "                      .format(valid_loss_min,\n",
    "                              valid_loss))\n",
    "                \n",
    "                torch.save(model.state_dict(),save_path)\n",
    "                valid_loss_min = valid_loss\n",
    "                \n",
    "            return model\n",
    "        \n",
    "    def test(self, loaders, model, criterion, use_cuda):\n",
    "        \"\"\"returns accuracy and loss\"\"\"\n",
    "        test_loss = 0.\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        \n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "            if self.use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions to true label\n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "            accuracy = 100. * correct / total\n",
    "        print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "        print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
    "        \n",
    "        return accuracy, test_loss\n",
    "        \n",
    "    def vgg16_model(self):\n",
    "        \"\"\"returns a vgg module after fine tunning the last layer\"\"\"\n",
    "        vgg16 = models.vgg16(pretrained=True)  \n",
    "        for param in vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "        input_size = vgg16.classifier[0].in_features\n",
    "        hidden_sizes = [2048, 1024]\n",
    "        output_size = 133\n",
    "        tuned_classifier = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.25),\n",
    "                         nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.25),\n",
    "                         nn.Linear(hidden_sizes[1], output_size),\n",
    "                         nn.LogSoftmax(dim=1))\n",
    "        vgg16.classifier = tuned_classifier\n",
    "        if self.use_cuda:\n",
    "            vgg16.cuda()\n",
    "            \n",
    "        return vgg16\n",
    "    \n",
    "    def predict_breed_transfer(self, img_path= None):\n",
    "        \"\"\" return the breed type \"\"\"\n",
    "        class_names = [item[4:].replace(\"_\", \" \") for item in self.dataset['train_data'].classes]\n",
    "        if img_path == None:\n",
    "            img_path = self.img_path\n",
    "            \n",
    "        image = Image.open(img_path)\n",
    "        in_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                           transforms.RandomResizedCrop(224),transforms.ToTensor()])\n",
    "        image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "        vgg16 = self.vgg16_model() \n",
    "        model_transfer.load_state_dict(torch.load('model_transfer.pt'))\n",
    "        vgg16.eval()  \n",
    "        output= vgg16(image)\n",
    "        idx = torch.argmax(output)\n",
    "        breed = class_names[idx]   \n",
    "        return breed\n",
    "    \n",
    "    \n",
    "    def run_app(self, img_path= None):\n",
    "\n",
    "        if img_path == None:\n",
    "            img_path = self.img_path\n",
    "            \n",
    "        input_ = self.predict_breed_transfer(img_path)\n",
    "        if self.face_detector(img_path):\n",
    "            title = 'Our prediction is that this photo belong to human but it looks like: {}'\n",
    "            .format(input_)\n",
    "        elif self.dog_detector(img_path):\n",
    "            title = 'This is dog of type: {}'.format(input_)\n",
    "        else:\n",
    "            title = 'ERROR'\n",
    "        \n",
    "        return title\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
